# yaml-language-server: $schema=public/schemas/brainhack-config.json
event:
  year: 2023
  startDate:
    day: 1
    month: 11
    year: 2023
  endDate:
    day: 3
    month: 11
    year: 2023
displaySections:
  tutorial: false
  schedule: false
  twitterFeed: true
twitterUrl: https://twitter.com/uwobrainhack
faq:
  - question: What is a "Brainhack"?
    answer: |
      Brainhack is an academically oriented hackathon which connects researchers
      from across many different disciplines to work together on innovative
      projects related to neuroscience. For more details and examples of past
      Brainhack projects click
      [here](https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0121-x).
  - question: Who can participate?
    answer: |
      Any students (undergraduate/graduate), post-docs, staff, faculty, or
      clinicians with an interest in coding, neuroscience or neuroimaging are
      encouraged to participate.
  - question: Will the event be in-person or virtual?
    answer: |
      Brainhack Western 2023 will be in-person as Western University policies
      allow. Tutorials will be hybrid, however, only virtual attendees will be
      given access to the Zoom room links.  Virtual participation for in-person
      attendees will be granted if you are required to self-isolate due to
      illness or have a primary workplace outside of the greater London, ON
      area.
  - question: |
      I am interested in attending a specific tutorial in-person. How do I do
      that?
    answer: |
      You will have the opportunity to build a schedule during registration by
      specifying which tutorials you wish to attend.  However, provided Western
      University does not re-implement room capacity limits, you should be able
      to attend any tutorials you wish.
  - question: What COVID-19 rules and restrictions will be in place?
    answer: |
      Brainhack Western 2023 will be following all Western University campus
      rules regarding COVID-19.  This includes mandatory COVID-19 vaccination
      for anyone coming on campus and masking when attending tutorials or in
      hacking rooms.
  - question: What does registration include?
    answer: In-person registration includes access to all in-person tutorials and the ability to join an in-person hacking project group. In-person registration also includes breakfast, lunch, and snacks on all three days. Virtual attendees will be provided with zoom links that will allow them to attend any or all tutorials.
  - question: Do I need to register if I only want to hack?
    answer: |
      Yes! Anyone wishing to participate in any aspect of Brainhack Western
      2022, even just hacking, needs to register.
  - question: How much does it cost?
    answer: The cost of the event is $5 CAD!
  - question: |
      Is it possible to attend if I am not affiliated with Western University?
    answer: |
      We are able to accommodate non-Western University affiliated attendees.
      Please note that all attendees will need to follow Western University
      COVID-19 campus rules, which include being fully vaccinated and masking in
      classroom settings. We reserve the right to inspect COVID-19 vaccination
      records for non-Western affiliated attendees. Note that Brainhack Western
      does not offer travel stipends. Attendees traveling to London, ON are
      wholly responsible for their own travel, lodging, and any meals not
      already included with registration.
  - question: Will there be food?
    answer: |
      Yes! For on-site attendees, breakfast, lunch, snacks, non-alcoholic
      beverages, and coffee will be provided throughout the event. Please
      indicate any dietary restrictions when you register. Also, to cut down on
      waste, please bring your own coffee mug and/or water bottle.
  - question: What should I bring?
    answer: |
      Please bring your own laptop, cables, chargers, USB sticks, and some form
      of identification (e.g. Student card or Driver's licence). Also bring
      anything else you may need to work on your project (hardware, datasets
      etc.).
  - question: What if I don't know how to code?
    answer: |
      Learning is an important component of a Brainhack. There will be tutorials
      and experts around to answer questions.
  - question: What if I can't attend all three days?
    answer: |
      You are welcome to attend as much or as little as your schedule allows.
      We understand that Brainhack Western 2022 is scheduled during a busy part
      of the academic year, so we have tried to scheduled breaks each day to
      give attendees time to decompress and attend to their own work.
forms:
  registration:
    type: cognito
    title: Brainhack 2023 Registration
    shortTitle: Registration
    embedTag: <script src="https://www.cognitoforms.com/f/seamless.js" data-key="dKVrRkF3yk6PnoRpFF7XGg" data-form="4"></script>
    prefillMappings:
      id: Calculations.VolunteerCode
registration:
  cost: 5
  url: /forms/registration
  emailSignupTarget: https://hook.us1.make.com/hrdtv28jy9i55havi84l6db2xc1ieyol
  openDate:
    day: 18
    month: 9
    year: 2023
  closeDate:
    day: 13
    month: 10
    year: 2023
location:
  name: Western Interdisciplinary Research Building
  street: Perth Dr
  city: London
  province: "ON"
  url: "https://www.uwo.ca/bmi/about/wirb.html"
  maps_id: ChIJCVSloavvLogR82_w3v729s0
organizers:
  - Suzanne Witt
  - Tristan Kuehn
  - Farrah Mushtaha
  - Keza Motlana
  - Peter Van Dyken
  - Ali Khan
sponsors:
  - img: "/img/brainscan_logo.png"
    name: Brainscan
    url: "https://brainscan.uwo.ca"
schedule:
  - name: Tutorials
    startTime: 8
    endTime: 17
    days:
      - day: 30
        month: 11
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - name: Welcome & Project Pitches
            time: "9:00"
            duration: "1:00"
            color: blue
            room:
              - WIRB 1170
          - name: Lunch
            time: "12:00"
            duration: "1:30"
            room: WIRB 4190
          - tutorial: git
            time: "10:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1170
          - tutorial: mri
            time: "13:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 4190
          - tutorial: data-management
            time: "15:00"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 4190
      - day: 1
        month: 12
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - tutorial: reproducability
            time: "9:00"
            duration: "1:00"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 4190
          - tutorial: bias
            time: "10:00"
            duration: "1:00"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 3000
          - tutorial: data-mining
            time: "12:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 4190
          - tutorial: behaviour
            time: "12:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1110
          - tutorial: data-viz
            time: "15:00"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1170
          - name: Lunch
            time: "11:00"
            duration: "1:30"
            room: WIRB 4190
      - day: 2
        month: 12
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - tutorial: anat
            time: "9:00"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1130
          - tutorial: eeg
            time: "10:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1120
          - tutorial: fanbids
            time: "10:30"
            duration: "1:30"
            color: "#1f331e"
            priority: 1
            room:
              - WIRB 1160
          - name: Anatomy Drop-in Demos
            time: "10:30"
            duration: "1:30"
            color: "#1f331e"
            room: WIRB 1130
          - name: Lunch
            time: "12:00"
            duration: "1:30"
            room: WIRB Atrium
          - name: Project presentations & Wrap-up
            time: "15:00"
            duration: "1:00"
            color: blue
            room:
              - WIRB 1170
  - name: Hacking
    startTime: 8
    endTime: 17
    days:
      - day: 30
        month: 11
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - name: Welcome & Project Pitches
            time: "9:00"
            duration: "1:00"
            color: blue
            room:
              - WIRB 1170
          - name: Lunch
            time: "12:00"
            duration: "1:30"
            room: WIRB 4190
          - name: Hacking
            time: "10:00"
            duration: "2:00"
            color: red
            room: WIRB 4190
          - name: Hacking
            time: "13:30"
            duration: "3:30"
            color: red
            room: WIRB 1160
          - name: Hacking
            time: "13:30"
            duration: "2:00"
            color: red
            room: WIRB 1120
          - name: Hacking
            time: "15:00"
            duration: "1:30"
            color: red
            room: WIRB 1110
      - day: 1
        month: 12
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - name: Lunch
            time: "11:00"
            duration: "1:30"
            room: WIRB 4190
          - name: Hacking
            time: "9:00"
            duration: "1:00"
            color: red
            room: WIRB 1130
          - name: Hacking
            time: "14:00"
            duration: "2:30"
            color: red
            room: WIRB 4190
          - name: Hacking
            time: "13:00"
            duration: "4:00"
            color: red
            room: WIRB 1160
      - day: 2
        month: 12
        year: 2022
        events:
          - name: Breakfast
            time: "8:00"
            duration: "1:00"
            room: WIRB 4190
          - name: Lunch
            time: "12:00"
            duration: "1:30"
            room: WIRB Atrium
          - name: Hacking
            time: "9:00"
            duration: "2:00"
            color: red
            room: WIRB 4190
          - name: Hacking
            time: "12:00"
            duration: "3:00"
            color: red
            room: WIRB 1120
          - name: Project presentations & Wrap-up
            time: "15:00"
            duration: "1:00"
            color: blue
            room:
              - WIRB 1170
tutorials:
  - id: fanbids
    name: FANBIDS
    organizer: Kevin Stubbs
    description: |
      FANBIDS is a collection of guidelines and MATLAB utilities that extends
      the benefits of BIDS to fNIRS data at every stage of processing. The
      framework is not tied to any single toolbox and aims to eventually
      facilitate cross-toolbox interactions. The primary benefits include:

      1. Producing file structures that are intuitive, descriptive, and portable
      2. Scaling well to large datasets 3. Promoting an ecosystem of widely
      compatible tools

      Two fully functional example tools will be presented: cardiac-based
      channel screening and a figure generation module. A workflow manager that
      applies the framework will also be shown.
  - id: eeg
    name: The Brain in Time
    image: /img/eeg.png
    organizer: Diana Dima
    description: |
      This tutorial will cover the basics of EEG data analysis, with a focus on
      how we can use tools from machine learning and computer vision to
      investigate rich spatiotemporally resolved datasets. There will be an
      interactive component allowing participants to look at real EEG data and
      try out analysis steps.
  - id: data-mining
    name: Data Mining
    organizer: Suzanne Witt
    description: |
      Meta-analyses of neuroimaging data are a good way to get started with
      understanding neuroimaging and task-based neural processing, as well as
      answer research questions that may not be easily addressed with by
      traditional data collection. This tutorial will cover the various aspects
      of designing a meta-analysis and some of the more popular methods,
      including both topic- and contrast-based meta-analyses and coordinate- and
      image-based meta-analyses. Some hands-on work with the python-based tool
      NiMARE with a sample dataset will be included to help attendees appreciate
      some of the nuances between the various types of meta-analyses. A new,
      web-driven, all-in-one meta-analysis toolbox will also be introduced.
  - id: git
    name: Demystifying Git and Github
    image: /img/git-logo.png
    organizer: Suzanne Witt
    description: |
      Git offers a simple and powerful way to track changes and automatically
      version control scripts and workflows, making collaborative coding much
      simpler. This hands-on tutorial will introduce new Git and GitHub users to
      the basics of the three-stage directory structure of Git, commits,
      branching, merge conflicts, forking, and pull requests. Both basic command
      line and GUI-based approaches will be covered. This tutorial is designed
      for people with little to no prior experience with Git and GitHub. More
      advanced topics, such as Git actions, will be mentioned but not covered.
      Come prepared with a GitHub account and and GitHub desktop installed
      (https://desktop.github.com). It is not necessary to install the Git
      sourcecode. (See https://git-scm.com/downloads/guis for a more complete
      list of GUI-based Git clients.)
  - id: data-management
    name: Research Data Management
    image: /img/datalad.png
    organizer: Tristan Kuehn
    description: |
      Handling data can be a challenge, and it's best to think about it before
      you need to organize it on a deadline. In this tutorial you'll learn best
      practices for collecting, storing, processing, and sharing your data.
      We'll go over writing a Data Management Plan, formatting your data with
      BIDS and other open standards, and version controlling your data with
      DataLad, and uploading to a public repository.
  - id: data-viz
    name: Data Visualization
    image: /img/matplotlib_small.png
    organizer: Tristan Kuehn
    description: |
      A great data visualization can effectively demonstrate the arguments
      you're making in a paper. In this tutorial you'll learn about designing
      informative graphics, and how to use one of a selection of tools to
      combine your design and data into a paper-ready graphic. We'll go over
      tools in Python, but most of the concepts should be transferable to your
      toolset of choice.
  - id: reproducability
    name: Reproducible Data Analysis
    image: /img/snakemake_reproducable.png
    organizer: Tristan Kuehn
    description: |
      Using a workflow management tool to run your research analyses can make it
      much easier to remember what you've done with your data, make small
      adjustments, and describe your analyses to others in a reproducible way.
      In this tutorial, you'll learn about what a workflow management tool is,
      why you might want to use one, and how to write your analyses as
      workflows. As an example, we'll go over SnakeBIDS, a Western-grown
      workflow management tool for handling BIDS-formatted neuroimaging data.
  - id: bias
    name: Unintended Racial Bias in Predictive Modeling
    organizer: Suzanne Witt
    panelists:
      - Lindsay Bodell
      - Luke Stark
      - Dan Lizotte
    description: |
      Come hear both psychology and data science faculty discuss the
      implications of a recently published paper, _Cross-ethnicity/race
      generalization failure of behavioral prediction from rest-state functional
      connectivity_
      ([DOI:10.1126/sciadv.abj1812](https://doi.org/10.1126/sciadv.abj1812)).
      This paper addresses how machine learning algorithms may increase, rather
      than alleviate, bias and unfairness against equity-deserving populations.
      Learn why collecting diverse study populations is important for the
      generalizability of results and how naively applying machine learning
      algorithms to large datasets may lead to the perpetuation of unfair biases
      against minority populations. Also, learn about inherent biases that may
      exist in many commonly used measurement techniques and tools.
  - id: mri
    name: A Brief Introduction to MRI
    image: /img/fmri.png
    organizer: Brad Karat
    description: |
      This tutorial will provide a basic introduction to MRI. We will cover
      where the MRI signal is originating from, what are the different
      contrasts, basic pulse sequences for acquiring an image, how to
      reconstruct and visualize an image from DICOM to NIFTI, and unique MRI
      contrasts such as diffusion or functional imaging.
  - id: behaviour
    name: Modern Realities of Behavioural Research
    organizer:
      - Priya Kalra
      - Anthony Cruz
    description: |
      This tutorial will cover the basics of behavioral data collection and
      analysis in neuroscience-adjacent fields such as cognitive psychology. The
      session will provide a broad overview of the topic, ranging from basics of
      behavioral experiment design, stimulus presentation, and data collection
      and analysis, to emerging data analysis techniques and online data
      collection. Throughout, the software options available for each step will
      be briefly discussed. No previous knowledge or experience is expected.
  - id: anat
    name: "Neuroanatomy for Researchers: a Focus on Surgical Targets"
    organizer: Alaa Taha
    image: "/img/afids.png"
    description: |
      In this tutorial, we will begin with a basic introduction to neuroanatomy
      then briefly discuss the hippocampus, basal ganglia structures, midbrain,
      and relatively uncharted zona incerta. Taking on a clinical lens, we will
      explore how these structures could be crucial targets during functional
      neurosurgical procedures.

      We end our tutorial with 3 mini-software demo stations:

      1. Learning neuroanatomy using an open and validated anatomical fiducial
         framework ([AFIDs](https://validator.afids.io/))
      2. Reviewing introduced anatomy in the context of a surgical case using a
         virtual reality headset
      3. Applying our functional neuroanatomy knowledge to plan a surgical case
         using a fully open-source software
         ([trajectoryGuide](https://trajectoryguide.greydongilmore.com/)).
projects:
  2022:
    - title: Safer Multimodal Teleoperation of (Simulated) Robots
      organizers:
        - name: Pranshu Malik
          github: "pranshumalik14"
      description: |
        Being confused, freezing, or panicking while trying hard to stop,
        re-direct, or stabilize a drone (or any such robot/toy) in sudden
        counter-intuitive poses or environmental conditions is likely a
        relatable experience for all of us. The idea here is about enhancing the
        expression of our intent while controlling a robot remotely — either in
        real life or on a computer screen (simulation) — while not replacing the
        primary instrument of control (modality) but instead by also integrating
        our brain states (thought) in the control loop as measured, for example,
        through EEG. Specifically, for the scope of the hackathon, this could
        mean developing a brain-machine interface for automatically assisting
        the operator in emergency cases with “smart” control command reflexes or
        “takeovers”. Such an approach can be beneficial in high-risk cases such
        as remote handling of materials in nuclear facilities or it can also aid
        the supervision of autonomous control, say in the context of
        self-driving cars, to ultimately increase safety.

        For now, we could pick a particular type of simulated robot (industrial
        arms, RC cars, drones, etc.) and focus on designing and implementing a
        paradigm for characterizing intended motion and surprise during
        undesired motion in both autonomous (with no user control but robot's
        self- and environmental influences) or semi-autonomous cases (including
        user's control commands), i.e., we can aim to measure intent and
        surprise given the user's control commands, the brain states, and robot
        states during algorithmically curated cases of robot motion. This will
        help us detect such situations and also infer desired reactions to
        accordingly adjust control commands to achieve desired reactions during
        emergencies and, more generally, to augment real-time active control to
        match the desired motion. We can strive to keep the approach suitable
        for generalizing well enough to robots of other types and/or
        morphologies and to more unusual environments.
    - title: "Brain3DVis: AR/MR MRI Visualizer"
      organizers:
        - name: Liam Bilbie
          github: LiamBilbie
      description: |
        Application that uses a web-based front end where users can submit brain
        MRI volumes. The data is then processed on the application backend, a 3D
        model is generated, and is then accessible in a AR/VR environment. We
        are using the MERN stack for the web component and C#/Unity for the
        AR/VR application. We would love to work with people who have experience
        with MRI volumetric segmentation or are interested in VR/AR data
        visualization. :slightly_smiling_face:
    - title: "Functional Atlas Explorer"
      organizers:
        - name: Caroline Nettekoven
          github: carobellum
        - name: Ladan Shahshahani
          github: lshahsha
      description: |
        "What does the inferior frontal gyrus do?" Googling this question
        returns 93,400,000 results. A skim read of paper abstracts will give you
        some ideas about its functions. But wouldn't it be useful to have an
        interactive map where you can explore these functions in the brain?
        Imagine clicking on a brain region and getting a word cloud of functions
        that this region is highly involved in. That's what we will build!

        We will create an interactive tool, useful for anyone wanting to explore
        their own functional data or openly available functional datasets.
        Together with our functional fusion toolbox (in-house & soon to be
        released), it lets you integrate information from many different openly
        available datasets (Human Connectome Project, etc).

        During the project you will be able to use our existing toolbox to
        explore these large datasets - as well as your own data! In addition,
        this interactive map will provide a side by side view of your desired
        brain regions and their connections with other brain regions. Click on a
        region and you get a map of its functional connectivity to all other
        regions in the brain.

        The tool will help synthesize findings across studies (think Neurosynth,
        but directly based on fMRI data) and aid interpretation of results as
        well as planning of future experiments.
    - title: "DWI Fiducials"
      organizers:
        - name: Arun Thurairajah
      description: |
        Diffusion-Weighted Imaging (DWI) is a variant of the standard MRI
        sequence examining the diffusion rate of water molecules.  DWI or
        Diffusion MRI has allowed for the improved study of white matter
        pathways across both diseased and healthy patients.

        The goal of the diffusion Fiducials or dFIDs project is to identify a
        set of anatomical landmarks on a variety of Diffusion-Weighted MRI
        images that are both salient and have functional significance.  This
        will be an extension of the previous Anatomical Fiducials (AFIDs)
        project that has localized a set of 32 clinically-relevant landmarks in
        humans, macaques, and PD patients in multiple imaging acquisitions (see
        https://doi.org/10.1002/hbm.24693).

        We are looking for students, researchers, and clinicians to determine
        potential fiducials across various acquisition types and models in DWI.
        Those with experience in acquiring diffusion images or who have an
        interest in neuroimaging or anatomy are welcome to join!
  2023:
    - title: Functional Atlas Explorer
      description: |-
        "What does the inferior frontal gyrus do?" Googling this question returns 93,400,000 results. A skim read of paper abstracts will give you some ideas about its functions. But wouldn't it be useful to have an interactive map where you can explore these functions in the brain? Imagine clicking on a brain region and getting a word cloud of functions that this region is highly involved in. That's what we will build!

        We will create an interactive tool, useful for anyone wanting to explore their own functional data or openly available functional datasets. Together with our functional fusion toolbox (in-house & soon to be released), it lets you integrate information from many different openly available datasets (Human Connectome Project, etc).

        During the project you will be able to use our existing toolbox to explore these large datasets - as well as your own data! In addition, this interactive map will provide a side by side view of your desired brain regions and their connections with other brain regions. Click on a region and you get a map of its functional connectivity to all other regions in the brain.

        The tool will help synthesize findings across studies (think Neurosynth, but directly based on fMRI data) and aid interpretation of results as well as planning of future experiments.
      organizers:
        - name: Peter VD
          github: pvandyken
